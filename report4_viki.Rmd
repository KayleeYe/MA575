---
title: "report4"
author: "Viktoria Zruttova"
date: "2024-04-07"
output: html_document
---
```{r}
library(car)
library(caret)
library(ggplot2)
library(dplyr)
library(GGally)
library(readxl)
library(MLmetrics)
```


```{r}
#load the dataset
mydata <- read.csv('./data/day.csv')

```

```{r}
#convert 'dteday' column to Date format
mydata$dteday <- as.Date(mydata$dteday)

#season
mydata$season <- cut(mydata$season,
                     breaks = c(0.5, 1.5, 2.5, 3.5, 4.5),
                     labels = c("Winter", "Spring", "Summer", "Fall"))
mydata$season <- factor(mydata$season, levels = c("Winter", "Spring", "Summer", "Fall"))

#workingday
mydata$workingday <- ifelse(mydata$workingday == 0, "Not_Workingday", "Workingday")
mydata$workingday <- factor(mydata$workingday, levels = c("Not_Workingday", "Workingday"))

#weather
mydata$weathersit <- cut(mydata$weathersit,
                         breaks = c(0.5, 1.5, 2.5, 3.5, 4.5),
                         labels = c("Weather_1", "Weather_2", "Weather_3", "Weather_4"))
mydata$weathersit <- factor(mydata$weathersit, levels = c("Weather_1", "Weather_2", "Weather_3", "Weather_4"))

head(mydata)
```

We are splitting the dataset in 2 parts, first part is year 2011 and the second part is year 2012. Then we are splitting subset of year 2011 to be 50% training dataset and 50% validation dataset. The year 2012 dataset will be used for prediction.

```{r}
# Set a seed for reproducibility
# Setting a seed is crucial for reproducibility and consistency of results.
# It ensures that when you run the same code multiple times, you'll ...
# ... obtain the same results.
set.seed(20231103)
# Filter dataset for year 2011 (0) and year 2012 (1)
year2011 <- mydata[mydata$yr == 0, ]
year2012 <- mydata[mydata$yr == 1, ]

# Add 'Type' column and assign values
year2011$Type <- "Training"
year2012$Type <- "Validation"

# Combine training and validation data
mydata <- rbind(year2011, year2012)
```


We choose 3 questions of interest:

1. **How does working day affect the number of registered users?** where Y is the numnber of registered users
2. **How does season affect the number of casual users?** where Y is the sqrt(casual users)
3. **Is weather correlated to the number of bike rentals?* ** where Y is the count of bikes rented 

## Boxplots for proposed covariates y 


```{r}

#registered
ggplot(mydata, aes(x = Type, y = registered, color = Type)) +
  geom_boxplot(position = position_dodge(width = 0.8)) +
  labs(x = "Type", y = "# Registered Users") +
  scale_fill_manual(name = "Dataset Type", values = c("Training" = "blue", "Validation" = "red")) +
  ggtitle("# Registered Users by Type (Training vs. Validation)") +
  theme_bw()

#sqrt(casual)
ggplot(mydata, aes(x = Type, y = sqrt(casual), color = Type)) +
  geom_boxplot(position = position_dodge(width = 0.8)) +
  labs(x = "Type", y = "Square Root # Casual Users") +
  scale_fill_manual(name = "Dataset Type", values = c("Training" = "blue", "Validation" = "red")) +
  ggtitle("Square Root # Casual Users by Type (Training vs. Validation)") +
  theme_bw()

#cnt
ggplot(mydata, aes(x = Type, y = cnt, color = Type)) +
  geom_boxplot(position = position_dodge(width = 0.8)) +
  labs(x = "Type", y = "# Total Users") +
  scale_fill_manual(name = "Dataset Type", values = c("Training" = "blue", "Validation" = "red")) +
  ggtitle("# Total Users by Type (Training vs. Validation)") +
  theme_bw()

# Function to calculate statistics
calculate_statistics <- function(x) {
  return(c(
    Min = min(x, na.rm = TRUE),
    Q1 = quantile(x, 0.25, na.rm = TRUE),
    Median = median(x, na.rm = TRUE),
    Mean = mean(x, na.rm = TRUE),
    Q3 = quantile(x, 0.75, na.rm = TRUE),
    Max = max(x, na.rm = TRUE)
  ))
}


```


```{r}
#creating training data our of mydata (training -> data from 2011)
training_data <- subset(mydata, Type == "Training")
summary(training_data)
```
```{r}
#creating training data our of mydata (validatioin -> data from 2012)
validation_data <- subset(mydata, Type == "Validation")
summary(validation_data)
```



## Full models for each question
We are fitting full model which will be used to stepwise regression later. We address multicollinearity issue and delete variables that might cause it.

### Note: I am not sure which of the variables should be deleted and which should be kept in the model to make it better.

```{r}


full_model1 <- lm(registered ~ as.factor(workingday) + as.factor(season)+ holiday + weekday + temp + hum + windspeed + as.factor(weathersit),
                 data = training_data)

full_model2 <- lm( sqrt(casual)~ as.factor(workingday) + as.factor(season) + holiday + weekday + temp + hum + windspeed + as.factor(weathersit),
                 data = training_data)

full_model3 <- lm( cnt ~ casual +as.factor(workingday) + as.factor(season) + holiday + weekday + temp + hum + windspeed + as.factor(weathersit),
                 data = training_data)

summary(full_model1)
summary(full_model2)
summary(full_model3)

#plot added variables
avPlots(full_model1)
avPlots(full_model2)
avPlots(full_model3)
```


# Stepwise Regression

```{r}
stepwise_model1 <- step(full_model1, direction = "both")
stepwise_model2 <- step(full_model2, direction = "both")
stepwise_model3 <- step(full_model3, direction = "both")
```

```{r}
summary(stepwise_model1)
summary(stepwise_model2)
summary(stepwise_model3)
```
#### model 1: R^2 = 0.8075
#### model 2: R^2 = 0.8016
#### model 3: R^2 = 0.8928


```{r}
avPlots(stepwise_model1)
avPlots(stepwise_model2)
avPlots(stepwise_model3)
```

For vif, values close to 1 indicate no multicollinearity, values between 1-3 indicate mild collinearity which is not ideal but can be considered ok since it won't severaly impact the interpretability of the coefficients, values above indicate severe multicollinearity which is considered unreliable.

```{r}
vif(stepwise_model1)
vif(stepwise_model2)
vif(stepwise_model3)
```

### Prediction


```{r}
validation_data$predicted_registered <- predict(stepwise_model1, newdata = validation_data)
validation_data$predicted_sqrtcasual <- predict(stepwise_model2, newdata = validation_data)
validation_data$predicted_count <- predict(stepwise_model3, newdata = validation_data)
```


### Note: here in the predicitons I am unsure why the firts one is negative, in thesecond quetsion, I am unsure whether I should square the original value or not (not sure wthere it predicts the squared casaul count or not). In the third question, it produces Nans???

```{r}
observed_values1 <- validation_data$registered
predicted_values1 <- validation_data$predicted_registered
# Calculate different prediction performance metrics
# Functions from the MLmetrics package
# Common regression metrics
# Calculate the Root Mean Squared Error (RMSE), which measures the ...
# ... average magnitude of prediction errors.
# Lower is better.
rmse1 <- RMSE(predicted_values1, observed_values1)
# same as
# sqrt(mean((observed_values - predicted_values)^2))

# Compute the Mean Absolute Error (MAE), indicating the average absolute ...
# ... difference between predicted and observed values.
# Lower is better.
mae1 <- MAE(predicted_values1, observed_values1)
# same as
# mean(abs(observed_values - predicted_values))

# Calculate the Mean Absolute Percentage Error (MAPE), measuring the ...
# ... average percentage difference between predicted and observed values.
mape1 <- MAPE(predicted_values1, observed_values1)
# same as
# mean(abs(predicted_values-observed_values)/observed_values)

# Determine the R-squared (RÂ²) Score, representing the proportion of the ...
# ... variance in the observed values (of validation data set) ... 
# ... explained by the predicted values from the model.
# Higher is better.
r_squared1 <- R2_Score(predicted_values1, observed_values1)
# same as
# summary(lm(observed_values ~ predicted_values))$r.squared

# Display the calculated metrics
cat("Root Mean Squared Error (RMSE):", round(rmse1, digits = 4), "\n")
cat("Mean Absolute Error (MAE):", round(mae1, digits = 4), "\n")
cat("R-squared (R^2) Score:", round(r_squared1, digits = 4), "\n")
cat("Mean Absolute Percentage Error (MPE):", round(mape1, digits = 4), "\n")



#second question
observed_values2 <- sqrt(validation_data$casual) #should I transform it here??
predicted_values2 <- validation_data$predicted_sqrtcasual
rmse2 <- RMSE(predicted_values2, observed_values2)
mae2 <- MAE(predicted_values2, observed_values2)
mape2 <- MAPE(predicted_values2, observed_values2)
r_squared2 <- R2_Score(predicted_values2, observed_values2)
cat("Root Mean Squared Error (RMSE):", round(rmse2, digits = 4), "\n")
cat("Mean Absolute Error (MAE):", round(mae2, digits = 4), "\n")
cat("R-squared (R^2) Score:", round(r_squared2, digits = 4), "\n")
cat("Mean Absolute Percentage Error (MPE):", round(mape2, digits = 4), "\n")



#third question
observed_values3 <- validation_data$count
predicted_values3 <- validation_data$predicted_count
rmse3 <- RMSE(predicted_values3, observed_values3)
mae3 <- MAE(predicted_values3, observed_values3)
mape3 <- MAPE(predicted_values3, observed_values3)
r_squared3 <- R2_Score(predicted_values3, observed_values3)
cat("Root Mean Squared Error (RMSE):", round(rmse3, digits = 4), "\n")
cat("Mean Absolute Error (MAE):", round(mae3, digits = 4), "\n")
cat("R-squared (R^2) Score:", round(r_squared3, digits = 4), "\n")
cat("Mean Absolute Percentage Error (MPE):", round(mape3, digits = 4), "\n")


```





#### not working for model 3??

## Diagnostics of Training model
we **choose** model 1 because it has best RMSE and R^2 (it is done for whole 2011 year)

```{r}
#done on model 1
m.mlr <- lm(registered ~ as.factor(workingday) + as.factor(season) + holiday + 
    temp + hum + windspeed + as.factor(weathersit),
                 data = year2011)

```


```{r}
diagnostics_df <- data.frame(
  Residuals = resid(m.mlr),
  Fitted_Values = fitted(m.mlr),
  Standardized_Residuals = rstandard(m.mlr),
  Leverage = hatvalues(m.mlr)
  #Date = year2011$dteday
)

# Create the standardized residuals vs. fitted values plot
ggplot(diagnostics_df, aes(x = Fitted_Values, y = Residuals)) +
  geom_point(col="blue", alpha=0.75) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs( title = "Residuals vs. Fitted Values",
        x = "Fitted Values", y = "Residuals") +
  theme_bw()

# Create the QQ plot
ggplot(diagnostics_df, aes(sample = Standardized_Residuals)) +
  stat_qq(aes(sample = Standardized_Residuals), distribution = qnorm,
          size = 2, col="blue", alpha = 0.75) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
  labs(title = "Standardized Residual QQ Plot",
       x = "Theoretical Quantiles", y = "Sample Quantiles") +
  theme_bw()

# Create the sqrt(|standardized residuals|) vs. fitted values plot
ggplot(diagnostics_df, aes(x = Fitted_Values, y = sqrt(abs(Standardized_Residuals)))) +
  geom_point(col="blue", alpha=0.75) +
  labs( title = "Residuals vs. Fitted Values",
        x = "Fitted Values", y = "sqrt(|Standardized Residuals|)") +
  theme_bw()

# Leverage vs Standardized Residuals
ggplot(diagnostics_df, aes(x = Leverage, y = Standardized_Residuals)) +
  geom_point(alpha = 0.75) +
  labs(title = "Standardized Residuals vs. Leverage Plot",
       x = "Leverage", y = "Standardized Residuals") +
  theme_bw()

```
# Prediction


```{r}
validation2012<- subset(validation_data)
validation2012$predicted_registered <- predict(m.mlr, newdata = validation2012)
summary(validation2012$predicted_registered)

```


```{r}
# Extract observed and predicted values
observed_values <- validation2012$registered
predicted_values <- validation2012$predicted_registered
rmse <- RMSE(predicted_values, observed_values)
mae <- MAE(predicted_values, observed_values)
mape <- MAPE(predicted_values, observed_values)
r_squared <- R2_Score(predicted_values, observed_values)


cat("Root Mean Squared Error (RMSE):", round(rmse, digits = 4), "\n")
cat("Mean Absolute Error (MAE):", round(mae, digits = 4), "\n")
cat("R-squared (R^2) Score:", round(r_squared, digits = 4), "\n")
cat("Mean Absolute Percentage Error (MPE):", round(mape, digits = 4), "\n")
```


```{r}
ggplot(validation2012, aes(x = registered, y = predicted_registered)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(x = "Observed Values", y = "Predicted Values",
       title = "Observed vs. Predicted Values") +
  theme_bw()


# Residuals plot
ggplot(validation2012, aes(x = 1:nrow(validation2012), y = registered-predicted_registered)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 0, color = "red", linetype = "dashed") +
  labs(x = "Observation Index", y = "Residuals",
       title = "Observed vs. Predicted Values") +
  theme_bw()


```

